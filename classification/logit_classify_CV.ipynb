{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "642553f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import dataparser\n",
    "from ARMA import ARMA\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, ShuffleSplit\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c60864",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/Volumes/My Passport/AI_Research/data/physionet.org/files/chbmit/1.0.0/'\n",
    "patient_id = 'chb01'\n",
    "parser = dataparser.DataParser(rootdir, patient_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a73a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ictal_filenames = parser.seizure_filenames()\n",
    "preictal_filenames = [x for x in ictal_filenames if parser.check_preictal_interval_exists(x, parser.mins_in_secs(15))]\n",
    "interictal_filenames = parser.no_seizure_filenames()\n",
    "preictal_labels = np.ones((len(preictal_filenames)))\n",
    "interictal_labels = -1 * np.ones((len(interictal_filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88eb262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=6, random_state=None, shuffle=False)\n",
      "ShuffleSplit(n_splits=35, random_state=0, test_size=0.01, train_size=None)\n",
      "-\n",
      "Interictal TRAIN: [20 16 28 22 15 10  2 11 27 25 34 32 26 30  8 13  5 17 14 31 24  1 12  6\n",
      " 23  4 18 21 19  9  7 33  3  0] Interictal TEST: [29]\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load interictal train data:   0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interictal test data: (23, 921600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load interictal train data:  65%|██████▍   | 22/34 [00:13<00:10,  1.12it/s]"
     ]
    }
   ],
   "source": [
    "# Cross Validation and Shuffle Split\n",
    "X_preictal = np.array(preictal_filenames)\n",
    "y_preictal = np.array(preictal_labels)\n",
    "\n",
    "X_interictal = np.array(interictal_filenames)\n",
    "y_interictal = np.array(interictal_labels)\n",
    "\n",
    "kf = KFold(n_splits=6)\n",
    "kf.get_n_splits(X_preictal)\n",
    "print(kf)\n",
    "\n",
    "rs = ShuffleSplit(n_splits=len(interictal_filenames), test_size=.01, random_state=0)\n",
    "rs.get_n_splits(X_interictal)\n",
    "print(rs)\n",
    "\n",
    "print('-')\n",
    "\n",
    "for interictal_train_index, interictal_test_index in rs.split(X_interictal, y_interictal):\n",
    "    print(\"Interictal TRAIN:\", interictal_train_index, \"Interictal TEST:\", interictal_test_index)\n",
    "    print(\"---\")\n",
    "    # load interictal test data\n",
    "    interictal_test_filename = X_interictal[interictal_test_index].item()\n",
    "    interictal_test_filepath = rootdir + patient_id + '/' + interictal_test_filename\n",
    "    interictal_test_data = parser.data_all(interictal_test_filepath)\n",
    "    print('interictal test data:', interictal_test_data.shape)\n",
    "    # load interictal train data\n",
    "    interictal_train_filenames = [X_interictal[i] for i in interictal_train_index]\n",
    "    interictal_train_filepaths = [rootdir + patient_id + '/' + x for x in interictal_train_filenames]\n",
    "    interictal_train_data = []\n",
    "    for i in tqdm(range(len(interictal_train_filepaths)), desc='Load interictal train data'):\n",
    "        data = parser.data_all(interictal_train_filepaths[i])\n",
    "        interictal_train_data.append(data)\n",
    "    \n",
    "    for preictal_train_index, preictal_test_index in kf.split(X_preictal, y_preictal):\n",
    "        print(\"Preictal TRAIN:\", preictal_train_index, \"Preictal TEST:\", preictal_test_index)\n",
    "        print(\"---\")\n",
    "        # load preictal test data\n",
    "        preictal_test_filename = X_preictal[preictal_test_index].item()\n",
    "        preictal_test_filepath = rootdir + patient_id + '/' + preictal_test_filename\n",
    "        preictal_test_data = parser.data_all(preictal_test_filepath)\n",
    "        print('preictal test data:', preictal_test_data.shape)\n",
    "        # ---\n",
    "#         X_preictal_train, X_preictal_test = X_preictal[preictal_train_index], X_preictal[preictal_test_index]\n",
    "#         y_preictal_train, y_preictal_test = y_preictal[preictal_train_index], y_preictal[preictal_test_index]\n",
    "        # ---\n",
    "        # load preictal train data\n",
    "        preictal_train_filenames = [X_preictal[i] for i in preictal_train_index]\n",
    "        preictal_train_filepaths = [rootdir + patient_id + '/' + x for x in preictal_train_filenames]\n",
    "        preictal_train_data = []\n",
    "        for i in tqdm(range(len(preictal_train_filepaths)), desc='Load preictal train data'):\n",
    "            is_picked = parser.check_preictal_interval_exists(preictal_train_filenames, parser.mins_in_secs(15))\n",
    "            if is_picked:\n",
    "                start, end = parser.preictal_interval_times(preictal_train_filepaths[i], parser.mins_in_secs(15))\n",
    "                data = parser.data_interval(preictal_train_filepaths[i], start, end)\n",
    "                preictal_train_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aea8c84a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e9e972f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5ec6fff194a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mk_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m                                                \u001b[0;31m# Sequential buffer for time index in prediction point _k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mn_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m                                         \u001b[0;31m# Number of input channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m                                           \u001b[0;31m# Total number of input samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_scale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_i\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;31m# Initialise AR coefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sig' is not defined"
     ]
    }
   ],
   "source": [
    "# ARMA\n",
    "seed = 42\n",
    "fs = 256 # sampling frequency in Hz\n",
    "N = 500\n",
    "p = 2\n",
    "m = 5\n",
    "sig = \n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "fp = fs / N                                           # Prediction frequency\n",
    "t_s = 1 / fs                                               # Input signal time period\n",
    "\n",
    "a_k_list = []                                              # Sequential buffer for  MA samples\n",
    "a_h_k_list = []                                            # Sequential buffer for AR signal samples\n",
    "k_list = []                                                # Sequential buffer for time index in prediction point _k\n",
    "\n",
    "n_c = sig.shape[0]                                         # Number of input channels\n",
    "n = sig.shape[1]                                           # Total number of input samples\n",
    "a = a_scale * np.random.randn(n_c, n_i)               # Initialise AR coefficients\n",
    "c = m * np.ones(m)                               # Initialise MA coefficients\n",
    "c = c / c.sum()\n",
    "\n",
    "Ik = N                                                # Window width\n",
    "for _k in tqdm(range(Ik + n_i, n)):                         # Sliding window\n",
    "    if (_k % N == 0):                                 # Decimation policy: _k occurs once every N samples\n",
    "        w_start = _k - Ik - n_i + 1                   # Starting index of sliding window (end index is maintained by _k)\n",
    "        a_h = np.zeros((n_c, n_i))                    # AR parameter estimates from samples in window\n",
    "        for _i in range(n_c):                              # Iterate channels\n",
    "            x_t = sig[_i, w_start:_k]                       # Multi-channel window over input signal\n",
    "            N_w = len(x_t)\n",
    "            ymat = np.zeros((N_w - n_i, n_i))\n",
    "            yb = np.zeros((N_w - n_i, n_i))\n",
    "            for _c in range(n_i, 0, -1):                   # Past dependency of AR up to model order\n",
    "                ymat[ : , n_i - _c] = x_t[n_i - _c : -_c]\n",
    "            yb = x_t[n_i:]\n",
    "            a_h[_i] = np.linalg.pinv(ymat) @ yb            # Least squares solution to optimal parameters via Moore-Penrose Pseudo Inverse\n",
    "        a_k = np.zeros((n_c, n_i))\n",
    "        a_h_k_idx = len(a_h_k_list) - 1                    # Index to most recent block of AR parameters of shape: (n_c, n_i)\n",
    "        for _j in range(m):                                # MA smoothing of AR parameters going back m units of time, in timescale k\n",
    "            if len(a_h_k_list) > m:                        # Only begin smoothing once unit of time elapsed is greater than m\n",
    "                a_k = c[_j] * a_h_k_list[a_h_k_idx - _j]\n",
    "        k_list.append(_k)\n",
    "        a_h_k_list.append(a_h)\n",
    "        a_k_list.append(a_k)\n",
    "k = np.array(k_list)\n",
    "a_h_k = np.array(a_h_k_list)\n",
    "a_k = np.array(a_k_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a6dc69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
